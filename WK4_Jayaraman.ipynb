{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2366e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d4a8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1986a5",
   "metadata": {},
   "source": [
    "A Little note before the peer review:\n",
    "My aim for this was initially just houses >500k would be \n",
    "expensive = 1 and less than would be affordable =0. Instead of going this classification route I decided to specify a high value if their price per sqft > median price per sqft. There was another way I wanted to experiment with, which I will see too maybe in another notebook, but for this peer review I wanted to see how this method and line of thought worked out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd06fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_df = pd.read_csv(\"austinHousingData.csv\")\n",
    "austin_df.columns = austin_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386f822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_df = austin_df[(austin_df[\"latestPrice\"] > 0) & (austin_df[\"livingAreaSqFt\"] > 0)]\n",
    "austin_df[\"price_per_sqft\"] = austin_df[\"latestPrice\"] / austin_df[\"livingAreaSqFt\"]\n",
    "median_price_per_sqft = austin_df[\"price_per_sqft\"].median()\n",
    "austin_df[\"is_high_value\"] = (austin_df[\"price_per_sqft\"] > median_price_per_sqft).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d188dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = austin_df.select_dtypes(include=[np.number])\n",
    "cols_to_drop = [col for col in ['zpid', 'price_per_sqft', 'is_high_value', 'latestPrice'] if col in numeric_df.columns]\n",
    "numeric_features = numeric_df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3126e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat([numeric_features, austin_df[\"is_high_value\"]], axis=1).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631ee1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.drop(columns=[\"is_high_value\"])\n",
    "y = model_df[\"is_high_value\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7c51ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      1517\n",
      "           1       0.76      0.74      0.75      1518\n",
      "\n",
      "    accuracy                           0.75      3035\n",
      "   macro avg       0.75      0.75      0.75      3035\n",
      "weighted avg       0.75      0.75      0.75      3035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9f3b8",
   "metadata": {},
   "source": [
    "link for the dataset can be found on kaggle here: https://www.kaggle.com/datasets/ericpierce/austinhousingprices/data\n",
    "\n",
    "One last thing to note. I vastly prefer the findings here than in another way I was contemplating classification here which was through defining luxury based on rules like num of bathrooms and garage spaces and school rating. Since these things are highly subjective it is hard to justify cutoff rules like in comparing a house with more bathrooms to ones with less but has a pool. This I have found lead to class imbalances. The \"hypothesis\" I tested above with price/sqft is a clean way to classify real estate models. It better differentiates value for money especially in a context where pricing for an apartment vs house is very different. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
